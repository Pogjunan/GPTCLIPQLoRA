# Base
torch>=2.2
torchvision>=0.17
numpy>=1.24
tqdm>=4.66
sentencepiece>=0.1.99
tokenizers>=0.15
datasets>=2.19
matplotlib>=3.8

# Optional (enable as you reach later weeks)
transformers>=4.41
accelerate>=0.31
deepspeed>=0.14
faiss-cpu>=1.8
langchain>=0.2
qdrant-client>=1.9
gradio>=4.0
wandb>=0.17

# FlashAttention is not pip-simple; see gpt2_mini/README.md for install notes.
